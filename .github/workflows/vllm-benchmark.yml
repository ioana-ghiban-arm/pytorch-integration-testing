name: vLLM Benchmark

on:
  schedule:
    # Run every 2 hours
    - cron: '0 */2 * * *'
  workflow_dispatch:
  pull_request:
    paths:
      - .github/workflows/vllm-benchmark.yml

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

jobs:
  benchmark-h100:
    name: Run vLLM benchmarks
    runs-on: linux.aws.h100.4
    environment: ${{ github.ref == 'refs/heads/main' && 'pytorch-x-vllm' || 'pytorch-x-vllm' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Checkout vLLM repository
        uses: actions/checkout@v4
        with:
          repository: vllm-project/vllm
          path: vllm-benchmarks/vllm
          ref: main
          fetch-depth: 0

      - name: Setup benchmark tests
        working-directory: vllm-benchmarks
        run: |
          # Set the list of benchmarks we want to cover in PyTorch infra
          cp -r benchmarks/*.json vllm/.buildkite/nightly-benchmarks/tests

      - name: Set GPU device name
        working-directory: vllm-benchmarks
        run: |
          export GPU_DEVICE=$(nvidia-smi -i 0 --query-gpu=name --format=csv,noheader | awk '{print $2}')
          echo "GPU_DEVICE=$GPU_DEVICE" >> $GITHUB_ENV

      - name: Check for last benchmark commit
        working-directory: vllm-benchmarks
        env:
          DOCKER_IMAGE_PREFIX: public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo
        run: |
          HEAD_BRANCH=main

          pushd vllm
          # Looking back the latest 100 commits is probably enough
          for i in {0..99}
          do
            # Check if image already exists, if it does then check an older one
            HEAD_SHA=$(git rev-parse --verify HEAD~${i})
            DOCKER_IMAGE="${DOCKER_IMAGE_PREFIX}:${HEAD_SHA}"

            if docker manifest inspect "${DOCKER_IMAGE}"; then
              break
            fi
          done
          popd

          echo "HEAD_SHA=$HEAD_SHA" >> $GITHUB_ENV

      - name: Setup GPU_FLAG for docker run
        run: |
          echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"

      - name: Setup SCCACHE_SERVER_PORT environment for docker run when on container
        run: |
          echo "SCCACHE_SERVER_PORT_DOCKER_FLAG=-e SCCACHE_SERVER_PORT=$((RUNNER_UID + 4226))" >> "${GITHUB_ENV}"

      - name: Run vLLM benchmark
        env:
          SCCACHE_BUCKET: ossci-compiler-cache-circleci-v2
          SCCACHE_REGION: us-east-1
          HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
          DOCKER_IMAGE: public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:${{ env.HEAD_SHA }}
        run: |
          set -x

          docker run \
            ${GPU_FLAG:-} \
            ${SCCACHE_SERVER_PORT_DOCKER_FLAG:-} \
            -e SCCACHE_BUCKET \
            -e SCCACHE_REGION \
            -e GPU_DEVICE \
            -e HUGGING_FACE_HUB_TOKEN \
            --ipc=host \
            --tty \
            --security-opt seccomp=unconfined \
            -v "${GITHUB_WORKSPACE}:/tmp/workspace" \
            -w /tmp/workspace \
            "${DOCKER_IMAGE}" \
            bash -xc "cd vllm-benchmarks/vllm; ls -lah; ls -lah .buildkite/nightly-benchmarks/tests; git diff"
